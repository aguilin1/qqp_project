{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7d72c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy nltk sklearn gensim pyemd keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285af388",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "We do some basic data cleaning including stemming (i.e. removing suffixes) and removing common words, tagging parts of speech, and finding the duplicate words between given question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f53bc7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/annguilinger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/annguilinger/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/annguilinger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected string or bytes-like object\n",
      "Ran into problem with data, removing question:\n",
      "id                                      105780\n",
      "qid1                                    174363\n",
      "qid2                                    174364\n",
      "question1       How can I develop android app?\n",
      "question2                                  NaN\n",
      "is_duplicate                                 0\n",
      "Name: 105780, dtype: object\n",
      "At least one of the passed list is empty.\n",
      "Ran into problem with data, removing question:\n",
      "id                                           108978\n",
      "qid1                                         178936\n",
      "qid2                                         178937\n",
      "question1                                         i\n",
      "question2       What questions to ask any drdummer?\n",
      "is_duplicate                                      0\n",
      "Name: 108978, dtype: object\n",
      "At least one of the passed list is empty.\n",
      "Ran into problem with data, removing question:\n",
      "id                                                       115347\n",
      "qid1                                                     188110\n",
      "qid2                                                      52215\n",
      "question1                                                     o\n",
      "question2       Where can I watch free streaming movies online?\n",
      "is_duplicate                                                  0\n",
      "Name: 115347, dtype: object\n",
      "At least one of the passed list is empty.\n",
      "Ran into problem with data, removing question:\n",
      "id                                                         151922\n",
      "qid1                                                       188110\n",
      "qid2                                                       238787\n",
      "question1                                                       o\n",
      "question2       What is this - â€œThis website/URL has been bloc...\n",
      "is_duplicate                                                    0\n",
      "Name: 151922, dtype: object\n",
      "At least one of the passed list is empty.\n",
      "Ran into problem with data, removing question:\n",
      "id                     198913\n",
      "qid1                   300250\n",
      "qid2                   188110\n",
      "question1       What is this?\n",
      "question2                   o\n",
      "is_duplicate                0\n",
      "Name: 198913, dtype: object\n",
      "expected string or bytes-like object\n",
      "Ran into problem with data, removing question:\n",
      "id                                        201841\n",
      "qid1                                      303951\n",
      "qid2                                      174364\n",
      "question1       How can I create an Android app?\n",
      "question2                                    NaN\n",
      "is_duplicate                                   0\n",
      "Name: 201841, dtype: object\n",
      "expected string or bytes-like object\n",
      "Ran into problem with data, removing question:\n",
      "id                                                         363362\n",
      "qid1                                                       493340\n",
      "qid2                                                       493341\n",
      "question1                                                     NaN\n",
      "question2       My Chinese name is Haichao Yu. What English na...\n",
      "is_duplicate                                                    0\n",
      "Name: 363362, dtype: object\n",
      "At least one of the passed list is empty.\n",
      "Ran into problem with data, removing question:\n",
      "id                                                         381124\n",
      "qid1                                                       512812\n",
      "qid2                                                       512813\n",
      "question1                                                      no\n",
      "question2       I have a BS and MPH and hate my job. I found t...\n",
      "is_duplicate                                                    0\n",
      "Name: 381124, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "data_file_location = \"./quora_duplicate_questions.tsv\"\n",
    "data = pd.read_csv(\n",
    "    data_file_location,\n",
    "    sep='\\t',\n",
    ")\n",
    "\n",
    "stemmed_q1s = []\n",
    "tagged_q1s = []\n",
    "stemmed_q2s = []\n",
    "tagged_q2s = []\n",
    "dups_all = []\n",
    "cs_all = []\n",
    "\n",
    "\n",
    "common_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for index, question in data.iterrows():\n",
    "    question1 = question.question1\n",
    "    question2 = question.question2\n",
    "\n",
    "    try:\n",
    "        tokens1 = [token for token in wordpunct_tokenize(question1) if token not in common_words]\n",
    "        stemmed1 = [stemmer.stem(word) for word in tokens1]\n",
    "        tagged1 = nltk.pos_tag(stemmed1)\n",
    "\n",
    "        tokens2 = [token for token in wordpunct_tokenize(question2) if token not in common_words]\n",
    "        stemmed2 = [stemmer.stem(word) for word in tokens2]\n",
    "        tagged2 = nltk.pos_tag(stemmed2)\n",
    "        \n",
    "        dups = [word for word in stemmed1 if word in stemmed2]\n",
    "        try:\n",
    "            cs = word_vectors.n_similarity(stemmed1,stemmed2)\n",
    "        except ValueError as er:\n",
    "            print(dups)\n",
    "            print(er)\n",
    "            cs = 0\n",
    "        \n",
    "        stemmed_q1s.append(stemmed1)\n",
    "        tagged_q1s.append(tagged1)\n",
    "        stemmed_q2s.append(stemmed2)\n",
    "        tagged_q2s.append(tagged2)\n",
    "        dups_all.append(len(dups))\n",
    "        cs_all.append(cs)\n",
    "\n",
    "    except Exception as e:\n",
    "        data.drop([index],inplace=True)\n",
    "        print(e)\n",
    "\n",
    "        print(\"Ran into problem with data, removing question:\")\n",
    "        print(question)\n",
    "        continue\n",
    "data.insert(4,'q1_stems',stemmed_q1s)\n",
    "data.insert(5,'q1_tags',tagged_q1s)\n",
    "data.insert(7,'q2_stems',stemmed_q2s)\n",
    "data.insert(8,'q2_tags',tagged_q2s)\n",
    "data.insert(9,'duplicates',dups_all)\n",
    "data.insert(10,'cosine_similarity',cs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fae80d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "\n",
      "                                            q1_stems  \\\n",
      "0  [what, step, step, guid, invest, share, market...   \n",
      "1  [what, stori, kohinoor, (, koh, -, -, noor, ),...   \n",
      "2  [how, i, increas, speed, internet, connect, us...   \n",
      "3         [whi, i, mental, lone, ?, how, i, solv, ?]   \n",
      "4  [which, one, dissolv, water, quikli, sugar, ,,...   \n",
      "\n",
      "                                             q1_tags  \\\n",
      "0  [(what, WP), (step, VB), (step, NN), (guid, NN...   \n",
      "1  [(what, WP), (stori, VBD), (kohinoor, NN), ((,...   \n",
      "2  [(how, WRB), (i, JJ), (increas, VBP), (speed, ...   \n",
      "3  [(whi, NN), (i, NN), (mental, VBP), (lone, NN)...   \n",
      "4  [(which, WDT), (one, CD), (dissolv, NN), (wate...   \n",
      "\n",
      "                                           question2  \\\n",
      "0  What is the step by step guide to invest in sh...   \n",
      "1  What would happen if the Indian government sto...   \n",
      "2  How can Internet speed be increased by hacking...   \n",
      "3  Find the remainder when [math]23^{24}[/math] i...   \n",
      "4            Which fish would survive in salt water?   \n",
      "\n",
      "                                            q2_stems  \\\n",
      "0  [what, step, step, guid, invest, share, market...   \n",
      "1  [what, would, happen, indian, govern, stole, k...   \n",
      "2       [how, internet, speed, increas, hack, dn, ?]   \n",
      "3  [find, remaind, [, math, ], 23, ^{, 24, }[/, m...   \n",
      "4       [which, fish, would, surviv, salt, water, ?]   \n",
      "\n",
      "                                             q2_tags  duplicates  \\\n",
      "0  [(what, WP), (step, VB), (step, NN), (guid, NN...           8   \n",
      "1  [(what, WP), (would, MD), (happen, VB), (india...          10   \n",
      "2  [(how, WRB), (internet, JJ), (speed, NN), (inc...           5   \n",
      "3  [(find, VB), (remaind, NN), ([, JJ), (math, NN...           2   \n",
      "4  [(which, WDT), (fish, NN), (would, MD), (survi...           4   \n",
      "\n",
      "   cosine_similarity  is_duplicate  \n",
      "0           0.985732             0  \n",
      "1           0.949585             0  \n",
      "2           0.929641             0  \n",
      "3           0.757050             0  \n",
      "4           0.942189             0  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "57f9cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1],data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9eebbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer=Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data.loc[:,['q1_stems','q2_stems']].to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9aa4d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenandpad(dat):\n",
    "    tokened = tokenizer.texts_to_sequences(dat.to_numpy())\n",
    "    return pad_sequences(tokened,maxlen=100,padding='post')\n",
    "\n",
    "q1s_train = tokenandpad(X_train.loc[:,'q1_stems'])\n",
    "q2s_train = tokenandpad(X_train.loc[:,'q2_stems'])\n",
    "\n",
    "q1s_test = tokenandpad(X_test.loc[:,'q1_stems'])\n",
    "q2s_test = tokenandpad(X_test.loc[:,'q2_stems'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ade78ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_137 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_138 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_90 (Embedding)       (None, None, 64)     6400        ['input_137[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_91 (Embedding)       (None, None, 64)     6400        ['input_138[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_50 (Bidirectiona  (None, 64)          24832       ['embedding_90[0][0]']           \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_51 (Bidirectiona  (None, 64)          24832       ['embedding_91[0][0]']           \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 128)          0           ['bidirectional_50[0][0]',       \n",
      "                                                                  'bidirectional_51[0][0]']       \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 64)           8256        ['concatenate_43[0][0]']         \n",
      "                                                                                                  \n",
      " input_139 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_140 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 1)            65          ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,785\n",
      "Trainable params: 70,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Embedding,Bidirectional,LSTM,concatenate\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "text_input1           = Input(shape = (None,), dtype = 'int32')\n",
    "embedding1            = Embedding(100,64)(text_input1)\n",
    "encoded_text1_forward = LSTM(32)\n",
    "encoded_text1_back    = LSTM(32, go_backwards=True)\n",
    "encoded_text1         = Bidirectional(encoded_text1_forward, backward_layer=encoded_text1_back)(embedding1)\n",
    "\n",
    "text_input2           = Input(shape = (None,), dtype = 'int32')\n",
    "embedding2            = Embedding(100,64)(text_input2)\n",
    "encoded_text2_forward = LSTM(32)\n",
    "encoded_text2_back    = LSTM(32, go_backwards=True)\n",
    "encoded_text2         = Bidirectional(encoded_text2_forward, backward_layer=encoded_text2_back)(embedding2)\n",
    "\n",
    "\n",
    "input3   = Input(shape = (None,), dtype = 'float32')\n",
    "input4   = Input(shape = (None,), dtype = 'float32')\n",
    "\n",
    "concatenated = concatenate([encoded_text1, encoded_text2], axis = -1)\n",
    "output = Dense(64, activation = 'relu')(concatenated)\n",
    "output = Dense(1,  activation = 'sigmoid')(output)\n",
    "\n",
    "model = Model([text_input1, text_input2, input3, input4], output)\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy', Precision(), Recall()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e2c4fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id    qid1    qid2  \\\n",
      "281837  281837  401653  177660   \n",
      "187348  187348  285555   54803   \n",
      "102770  102770  169988  169989   \n",
      "346916  346916  475313  475314   \n",
      "201186  201186  303128  303129   \n",
      "\n",
      "                                                question1  \\\n",
      "281837  What is the responsibility of a boater to prot...   \n",
      "187348  Somebody sent me an inappropriate snapchat. Wh...   \n",
      "102770    How do the Japanese feel about pre-marital sex?   \n",
      "346916              What are some of you favorite dreams?   \n",
      "201186  For what values of x, y, and n is (x+y)^n>x^n+...   \n",
      "\n",
      "                                                 q1_stems  \\\n",
      "281837      [what, respons, boater, protect, shorelin, ?]   \n",
      "187348  [somebodi, sent, inappropri, snapchat, ., what...   \n",
      "102770        [how, japanes, feel, pre, -, marit, sex, ?]   \n",
      "346916                          [what, favorit, dream, ?]   \n",
      "201186  [for, valu, x, ,, ,, n, (, x, +, )^, n, >, x, ...   \n",
      "\n",
      "                                                  q1_tags  \\\n",
      "281837  [(what, WP), (respons, VBZ), (boater, NN), (pr...   \n",
      "187348  [(somebodi, NN), (sent, VBD), (inappropri, NN)...   \n",
      "102770  [(how, WRB), (japanes, NNS), (feel, VBP), (pre...   \n",
      "346916   [(what, WP), (favorit, NN), (dream, NN), (?, .)]   \n",
      "201186  [(for, IN), (valu, NN), (x, NN), (,, ,), (,, ,...   \n",
      "\n",
      "                                                question2  \\\n",
      "281837                  Why do we need to be responsible?   \n",
      "187348  Someone deleted me on Snapchat so I deleted th...   \n",
      "102770  What is something that bothers you about Japan...   \n",
      "346916                       What is your favorite dream?   \n",
      "201186                        What is the value of x â€“ y?   \n",
      "\n",
      "                                                 q2_stems  \\\n",
      "281837                            [whi, need, respons, ?]   \n",
      "187348  [someon, delet, snapchat, i, delet, ., then, a...   \n",
      "102770          [what, someth, bother, japanes, peopl, ?]   \n",
      "346916                          [what, favorit, dream, ?]   \n",
      "201186                              [what, valu, x, â€“, ?]   \n",
      "\n",
      "                                                  q2_tags  duplicates  \\\n",
      "281837  [(whi, NNS), (need, VBP), (respons, NNS), (?, .)]           2   \n",
      "187348  [(someon, NN), (delet, NN), (snapchat, WP), (i...           4   \n",
      "102770  [(what, WP), (someth, VBZ), (bother, JJR), (ja...           2   \n",
      "346916   [(what, WP), (favorit, NN), (dream, NN), (?, .)]           4   \n",
      "201186  [(what, WP), (valu, NN), (x, NN), (â€“, NN), (?,...           5   \n",
      "\n",
      "        cosine_similarity  \n",
      "281837           0.812224  \n",
      "187348           0.942315  \n",
      "102770           0.806140  \n",
      "346916           1.000000  \n",
      "201186           0.804896  \n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7ea98b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 18:44:05.185695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:07.525617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:07.535982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:07.595403: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:07.595453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:10.738241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:10.774073: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:10.793771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:44:10.820554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6065/6065 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.6928 - precision: 0.6308 - recall: 0.4020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 18:59:39.140770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:59:39.453416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:59:39.453728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:59:39.477427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-17 18:59:39.480937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6065/6065 [==============================] - 1058s 172ms/step - loss: 0.5736 - accuracy: 0.6928 - precision: 0.6308 - recall: 0.4020 - val_loss: 0.5542 - val_accuracy: 0.7073 - val_precision: 0.6431 - val_recall: 0.4743\n",
      "Epoch 2/12\n",
      "6065/6065 [==============================] - 1053s 173ms/step - loss: 0.5436 - accuracy: 0.7113 - precision: 0.6420 - recall: 0.4899 - val_loss: 0.5366 - val_accuracy: 0.7171 - val_precision: 0.6424 - val_recall: 0.5355\n",
      "Epoch 3/12\n",
      "6065/6065 [==============================] - 952s 157ms/step - loss: 0.5284 - accuracy: 0.7223 - precision: 0.6504 - recall: 0.5335 - val_loss: 0.5276 - val_accuracy: 0.7255 - val_precision: 0.6351 - val_recall: 0.6115\n",
      "Epoch 4/12\n",
      "6065/6065 [==============================] - 895s 148ms/step - loss: 0.5185 - accuracy: 0.7296 - precision: 0.6580 - recall: 0.5546 - val_loss: 0.5190 - val_accuracy: 0.7299 - val_precision: 0.6511 - val_recall: 0.5861\n",
      "Epoch 5/12\n",
      "6065/6065 [==============================] - 963s 159ms/step - loss: 0.5102 - accuracy: 0.7349 - precision: 0.6639 - recall: 0.5686 - val_loss: 0.5163 - val_accuracy: 0.7330 - val_precision: 0.6687 - val_recall: 0.5559\n",
      "Epoch 6/12\n",
      "6065/6065 [==============================] - 924s 152ms/step - loss: 0.5037 - accuracy: 0.7390 - precision: 0.6683 - recall: 0.5795 - val_loss: 0.5108 - val_accuracy: 0.7363 - val_precision: 0.6764 - val_recall: 0.5546\n",
      "Epoch 7/12\n",
      "6065/6065 [==============================] - 938s 155ms/step - loss: 0.4982 - accuracy: 0.7426 - precision: 0.6733 - recall: 0.5862 - val_loss: 0.5112 - val_accuracy: 0.7364 - val_precision: 0.6813 - val_recall: 0.5441\n",
      "Epoch 8/12\n",
      "6065/6065 [==============================] - 922s 152ms/step - loss: 0.4932 - accuracy: 0.7462 - precision: 0.6775 - recall: 0.5942 - val_loss: 0.5062 - val_accuracy: 0.7404 - val_precision: 0.6703 - val_recall: 0.5907\n",
      "Epoch 9/12\n",
      "6065/6065 [==============================] - 1061s 175ms/step - loss: 0.4884 - accuracy: 0.7486 - precision: 0.6807 - recall: 0.5987 - val_loss: 0.5051 - val_accuracy: 0.7413 - val_precision: 0.6721 - val_recall: 0.5909\n",
      "Epoch 10/12\n",
      "6065/6065 [==============================] - 868s 143ms/step - loss: 0.4840 - accuracy: 0.7512 - precision: 0.6846 - recall: 0.6025 - val_loss: 0.5047 - val_accuracy: 0.7420 - val_precision: 0.6707 - val_recall: 0.5984\n",
      "Epoch 11/12\n",
      "6065/6065 [==============================] - 867s 143ms/step - loss: 0.4797 - accuracy: 0.7543 - precision: 0.6882 - recall: 0.6095 - val_loss: 0.5036 - val_accuracy: 0.7429 - val_precision: 0.6843 - val_recall: 0.5699\n",
      "Epoch 12/12\n",
      "6065/6065 [==============================] - 874s 144ms/step - loss: 0.4756 - accuracy: 0.7571 - precision: 0.6913 - recall: 0.6159 - val_loss: 0.5033 - val_accuracy: 0.7423 - val_precision: 0.6826 - val_recall: 0.5707\n"
     ]
    }
   ],
   "source": [
    "res = model.fit([q1s_train, q2s_train, X_train['cosine_similarity'], X_train['duplicates']], y_train.to_numpy(),\n",
    "           batch_size=50,\n",
    "           epochs=12,\n",
    "           validation_data=[[q1s_test, q2s_test, X_test['cosine_similarity'], X_test['duplicates']], y_test.to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3faff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
