{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978f956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (1.22.2)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.7.25-cp38-cp38-macosx_11_0_arm64.whl (282 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /Users/annguilinger/Library/Python/3.8/lib/python/site-packages (from nltk) (4.63.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Installing collected packages: regex, nltk\n",
      "\u001b[33m  WARNING: The script nltk is installed in '/Users/annguilinger/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nltk-3.7 regex-2022.7.25\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285af388",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "We do some basic data cleaning including stemming (i.e. removing suffixes) and removing common words, tagging parts of speech, and finding the duplicate words between given question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f53bc7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/annguilinger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/annguilinger/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/annguilinger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran into problem with data, removing question:\n",
      "id                                      105780\n",
      "qid1                                    174363\n",
      "qid2                                    174364\n",
      "question1       How can I develop android app?\n",
      "question2                                  NaN\n",
      "is_duplicate                                 0\n",
      "Name: 105780, dtype: object\n",
      "Ran into problem with data, removing question:\n",
      "id                                        201841\n",
      "qid1                                      303951\n",
      "qid2                                      174364\n",
      "question1       How can I create an Android app?\n",
      "question2                                    NaN\n",
      "is_duplicate                                   0\n",
      "Name: 201841, dtype: object\n",
      "Ran into problem with data, removing question:\n",
      "id                                                         363362\n",
      "qid1                                                       493340\n",
      "qid2                                                       493341\n",
      "question1                                                     NaN\n",
      "question2       My Chinese name is Haichao Yu. What English na...\n",
      "is_duplicate                                                    0\n",
      "Name: 363362, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "data_file_location = \"./quora_duplicate_questions.tsv\"\n",
    "data = pd.read_csv(\n",
    "    data_file_location,\n",
    "    sep='\\t',\n",
    ")\n",
    "\n",
    "stemmed_q1s = []\n",
    "tagged_q1s = []\n",
    "stemmed_q2s = []\n",
    "tagged_q2s = []\n",
    "dups_all = []\n",
    "\n",
    "\n",
    "common_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for index, question in data.iterrows():\n",
    "    question1 = question.question1\n",
    "    question2 = question.question2\n",
    "\n",
    "    try:\n",
    "        tokens1 = [token for token in wordpunct_tokenize(question1) if token not in common_words]\n",
    "        stemmed1 = [stemmer.stem(word) for word in tokens1]\n",
    "        tagged1 = nltk.pos_tag(stemmed1)\n",
    "\n",
    "        tokens2 = [token for token in wordpunct_tokenize(question2) if token not in common_words]\n",
    "        stemmed2 = [stemmer.stem(word) for word in tokens2]\n",
    "        tagged2 = nltk.pos_tag(stemmed2)\n",
    "        \n",
    "        dups = [word for word in stemmed1 if word in stemmed2]\n",
    "    except:\n",
    "        data.drop([index],inplace=True)\n",
    "        print(\"Ran into problem with data, removing question:\")\n",
    "        print(question)\n",
    "        continue\n",
    "    stemmed_q1s.append(stemmed1)\n",
    "    tagged_q1s.append(tagged1)\n",
    "    stemmed_q2s.append(stemmed2)\n",
    "    tagged_q2s.append(tagged2)\n",
    "    dups_all.append(dups)\n",
    "\n",
    "data.insert(4,'q1_stems',stemmed_q1s)\n",
    "data.insert(5,'q1_tags',tagged_q1s)\n",
    "data.insert(7,'q2_stems',stemmed_q2s)\n",
    "data.insert(8,'q2_tags',tagged_q2s)\n",
    "data.insert(9,'duplicates',dups_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fae80d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "\n",
      "                                            q1_stems  \\\n",
      "0  [what, step, step, guid, invest, share, market...   \n",
      "1  [what, stori, kohinoor, (, koh, -, -, noor, ),...   \n",
      "2  [how, i, increas, speed, internet, connect, us...   \n",
      "3         [whi, i, mental, lone, ?, how, i, solv, ?]   \n",
      "4  [which, one, dissolv, water, quikli, sugar, ,,...   \n",
      "\n",
      "                                             q1_tags  \\\n",
      "0  [(what, WP), (step, VB), (step, NN), (guid, NN...   \n",
      "1  [(what, WP), (stori, VBD), (kohinoor, NN), ((,...   \n",
      "2  [(how, WRB), (i, JJ), (increas, VBP), (speed, ...   \n",
      "3  [(whi, NN), (i, NN), (mental, VBP), (lone, NN)...   \n",
      "4  [(which, WDT), (one, CD), (dissolv, NN), (wate...   \n",
      "\n",
      "                                           question2  \\\n",
      "0  What is the step by step guide to invest in sh...   \n",
      "1  What would happen if the Indian government sto...   \n",
      "2  How can Internet speed be increased by hacking...   \n",
      "3  Find the remainder when [math]23^{24}[/math] i...   \n",
      "4            Which fish would survive in salt water?   \n",
      "\n",
      "                                            q2_stems  \\\n",
      "0  [what, step, step, guid, invest, share, market...   \n",
      "1  [what, would, happen, indian, govern, stole, k...   \n",
      "2       [how, internet, speed, increas, hack, dn, ?]   \n",
      "3  [find, remaind, [, math, ], 23, ^{, 24, }[/, m...   \n",
      "4       [which, fish, would, surviv, salt, water, ?]   \n",
      "\n",
      "                                             q2_tags  \\\n",
      "0  [(what, WP), (step, VB), (step, NN), (guid, NN...   \n",
      "1  [(what, WP), (would, MD), (happen, VB), (india...   \n",
      "2  [(how, WRB), (internet, JJ), (speed, NN), (inc...   \n",
      "3  [(find, VB), (remaind, NN), ([, JJ), (math, NN...   \n",
      "4  [(which, WDT), (fish, NN), (would, MD), (survi...   \n",
      "\n",
      "                                          duplicates  is_duplicate  \n",
      "0  [what, step, step, guid, invest, share, market...             0  \n",
      "1  [what, kohinoor, (, koh, -, -, noor, ), diamon...             0  \n",
      "2                 [how, increas, speed, internet, ?]             0  \n",
      "3                                             [?, ?]             0  \n",
      "4                            [which, water, salt, ?]             0  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b926c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
